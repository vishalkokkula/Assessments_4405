# -*- coding: utf-8 -*-
"""Anamoly_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ErNBGKrE9LguMJbuFVGXm597qR_sS1LI
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import IsolationForest

"""# load data"""

df = pd.read_csv('/content/anomaly_train.csv')
df

"""#Data pre processing"""

df.info()

df.isnull().sum()

df.duplicated().sum()

def outliers_iqr(df):
    q1 = np.percentile(df, 25)
    q3 = np.percentile(df, 75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    outliers = [x for x in df if x < lower_bound or x > upper_bound]
    return outliers
numerical_columns = df.select_dtypes(include=[np.number])
outliers_dict = {}
for col in numerical_columns.columns:
    outliers_dict[col] = outliers_iqr(df[col])
for col, outliers in outliers_dict.items():
    print("Outliers in column '{}': {}".format(col, outliers))

"""#EDA"""

df.shape

#correlation blw numerical colns:

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
correlation_matrix = df[numerical_columns].corr()
print(correlation_matrix)

#heat map
plt.figure(figsize=(20, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

#scatter
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

# histograms
for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

"""# model training and testing"""

df.head()

df['Type'].value_counts()

df['Location'].value_counts()

#anamoly detection

features = ['Amount','Type','Location']
X = df[features]
X.head()

X = pd.get_dummies(X)

model = IsolationForest(n_estimators=100, max_samples='auto', contamination=0.1)
model.fit(X)

df['anomaly_score'] = model.decision_function(X)
df.head()

df['result2'] = model.predict(X)
#df.head()

"""# metrics"""

plt.scatter(data = df, x = 'Amount',y = 'anomaly_score',c = 'result2')